import re
from typing import List, Optional, Callable

class MathRewardFunction:
    """数学问题奖励函数

    用于评估模型生成的数学答案是否正确。
    """

    def __init__(self, tolerance: float = 1e-4):
        """
        初始化奖励函数

        Args:
            tolerance: 数值比较的容差
        """
        self.tolerance = tolerance
        self.__name__ = "MathRewardFunction"  # 添加__name__属性

    def extract_answer(self, text: str) -> Optional[str]:
        """
        从文本中提取答案

        Args:
            text: 生成的文本

        Returns:
            提取的答案字符串，如果未找到则返回None
        """
        # 尝试多种答案格式
        patterns = [
            r"Final Answer:\s*([^\n]+)",
            r"####\s*([^\n]+)",
            r"答案是?\s*[:：]?\s*([^\n]+)",
            r"Therefore,?\s*(?:the answer is)?\s*([^\n]+)",
        ]

        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1).strip()

        # 如果没有找到特定格式，尝试提取最后一行的数字
        lines = text.strip().split('\n')
        for line in reversed(lines):
            numbers = re.findall(r'-?\d+\.?\d*', line)
            if numbers:
                return numbers[-1]

        return None

    def normalize_answer(self, answer: str) -> Optional[float]:
        """
        标准化答案为数值

        Args:
            answer: 答案字符串

        Returns:
            标准化后的数值，如果无法转换则返回None
        """
        if answer is None:
            return None

        # 移除常见的非数字字符
        answer = answer.strip()
        answer = answer.replace(',', '')  # 移除千位分隔符
        answer = answer.replace('$', '')  # 移除美元符号
        answer = answer.replace('%', '')  # 移除百分号

        # 提取数字
        numbers = re.findall(r'-?\d+\.?\d*', answer)
        if not numbers:
            return None

        try:
            return float(numbers[0])
        except ValueError:
            return None

    def compare_answers(self, pred: str, truth: str) -> bool:
        """
        比较预测答案和真实答案

        Args:
            pred: 预测答案
            truth: 真实答案

        Returns:
            是否匹配
        """
        pred_num = self.normalize_answer(pred)
        truth_num = self.normalize_answer(truth)

        if pred_num is None or truth_num is None:
            # 如果无法转换为数字，进行字符串比较
            return pred.strip().lower() == truth.strip().lower()

        # 数值比较（考虑容差）
        return abs(pred_num - truth_num) < self.tolerance

    def __call__(
            self,
            completions: List[str],
            **kwargs
    ) -> List[float]:
        """
        计算奖励

        Args:
            completions: 模型生成的完成文本列表
            **kwargs: 其他参数,必须包含ground_truth列表

        Returns:
            奖励值列表（1.0表示正确，0.0表示错误）
        """
        # 从kwargs中获取ground_truth
        ground_truths = kwargs.get("ground_truth", [])
        if not ground_truths:
            raise ValueError("ground_truth必须在数据集中提供")

        rewards = []

        for completion, truth in zip(completions, ground_truths):
            # 提取预测答案
            pred_answer = self.extract_answer(completion)

            # 比较答案
            if pred_answer and self.compare_answers(pred_answer, truth):
                reward = 1.0
            else:
                reward = 0.0

            rewards.append(reward)

        return rewards


def create_accuracy_reward(tolerance: float = 1e-4) -> Callable:
    """
    创建准确性奖励函数（便捷函数）

    Args:
        tolerance: 数值比较的容差

    Returns:
        奖励函数
    """
    reward_fn = MathRewardFunction(tolerance=tolerance)
    return reward_fn


def create_length_penalty_reward(
        base_reward_fn: Callable,
        max_length: int = 1024,
        penalty_weight: float = 0.1
) -> Callable:
    """
    创建带长度惩罚的奖励函数

    Args:
        base_reward_fn: 基础奖励函数
        max_length: 最大长度
        penalty_weight: 惩罚权重

    Returns:
        带长度惩罚的奖励函数
    """

    def reward_fn(completions: List[str], **kwargs) -> List[float]:
        # 计算基础奖励
        base_rewards = base_reward_fn(completions, **kwargs)

        # 添加长度惩罚
        final_rewards = []
        for reward, completion in zip(base_rewards, completions):
            length = len(completion)
            if length > max_length:
                penalty = penalty_weight * (length - max_length) / max_length
                reward = max(0.0, reward - penalty)
            final_rewards.append(reward)

        return final_rewards

    return reward_fn


def create_step_reward(
        base_reward_fn: Callable,
        step_bonus: float = 0.1
) -> Callable:
    """
    创建带步骤奖励的函数（鼓励详细的推理过程）

    Args:
        base_reward_fn: 基础奖励函数
        step_bonus: 每个推理步骤的奖励

    Returns:
        带步骤奖励的函数
    """

    def reward_fn(completions: List[str], **kwargs) -> List[float]:
        # 计算基础奖励
        base_rewards = base_reward_fn(completions, **kwargs)

        # 添加步骤奖励
        final_rewards = []
        for reward, completion in zip(base_rewards, completions):
            # 统计推理步骤（简单地统计换行符数量）
            num_steps = completion.count('\n')
            step_reward = min(step_bonus * num_steps, 0.5)  # 最多0.5的额外奖励
            final_rewards.append(reward + step_reward)

        return final_rewards

    return reward_fn